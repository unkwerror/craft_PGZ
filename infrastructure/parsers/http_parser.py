# infrastructure/parsers/http_parser.py - –ü–û–õ–ù–ê–Ø –≤–µ—Ä—Å–∏—è –¥–ª—è —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
import asyncio
import aiohttp
from bs4 import BeautifulSoup
import logging
from datetime import datetime
from decimal import Decimal
import re
from urllib.parse import urljoin, urlparse, quote
from tenacity import retry, stop_after_attempt, wait_exponential
from infrastructure.parsers.parser_interface import ParserInterface
from core.config import get_settings
from typing import Optional, Dict, Any, List

logger = logging.getLogger(__name__)

class HttpTenderParser(ParserInterface):
    """HTTP-–ø–∞—Ä—Å–µ—Ä –¥–ª—è zakupki.gov.ru - –¢–û–õ–¨–ö–û –†–ï–ê–õ–¨–ù–´–ï –î–ê–ù–ù–´–ï"""
    
    def __init__(self):
        self.settings = get_settings()
        self.base_url = "https://zakupki.gov.ru"
        self.session: Optional[aiohttp.ClientSession] = None
        
        # –ó–∞–≥–æ–ª–æ–≤–∫–∏ –∫–∞–∫ —É —Ä–µ–∞–ª—å–Ω–æ–≥–æ –±—Ä–∞—É–∑–µ—Ä–∞
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ru-RU,ru;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate, br',
            'DNT': '1',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache'
        }
    
    async def __aenter__(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ HTTP-—Å–µ—Å—Å–∏–∏"""
        timeout = aiohttp.ClientTimeout(total=45, connect=10)
        connector = aiohttp.TCPConnector(
            limit=5,
            limit_per_host=3,
            ttl_dns_cache=300,
            use_dns_cache=True,
            ssl=False  # zakupki.gov.ru –º–æ–∂–µ—Ç –∏–º–µ—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å SSL —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞–º–∏
        )
        
        self.session = aiohttp.ClientSession(
            headers=self.headers,
            timeout=timeout,
            connector=connector,
            cookie_jar=aiohttp.CookieJar()  # –°–æ—Ö—Ä–∞–Ω—è–µ–º cookies –¥–ª—è —Å–µ—Å—Å–∏–∏
        )
        
        logger.info("üåê HTTP session created for zakupki.gov.ru")
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.close()
            logger.info("üîí HTTP session closed")
    
    @retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=2, min=4, max=20))
    async def search_tenders(self,
                           query: str,
                           limit: int = 10,
                           filters: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """
        –†–ï–ê–õ–¨–ù–´–ô –ø–æ–∏—Å–∫ —Ç–µ–Ω–¥–µ—Ä–æ–≤ –Ω–∞ zakupki.gov.ru
        """
        logger.info(f"üîç REAL SEARCH on zakupki.gov.ru: '{query}', limit={limit}")
        
        if not self.session:
            raise RuntimeError("Session not initialized. Use 'async with' context manager.")
        
        # –°–Ω–∞—á–∞–ª–∞ –∏–¥–µ–º –Ω–∞ –≥–ª–∞–≤–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è cookies
        await self._initialize_session()
        
        try:
            # –¢–æ—á–Ω—ã–π URL —Å—Ç—Ä–∞–Ω–∏—Ü—ã –ø–æ–∏—Å–∫–∞ zakupki.gov.ru
            search_url = f"{self.base_url}/epz/order/extendedsearch/results.html"
            
            # –†–ï–ê–õ–¨–ù–´–ï –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞ –¥–ª—è zakupki.gov.ru (–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–µ –≤ 2025)
            params = {
                'morphology': 'on',
                'search-filter': '–î–∞—Ç–µ —Ä–∞–∑–º–µ—â–µ–Ω–∏—è',
                'pageNumber': 1,
                'sortDirection': 'false',
                'recordsPerPage': f'_{min(limit, 50)}',  # _10, _20, _50
                'showLotsInfoHidden': 'false',
                'sortBy': 'UPDATE_DATE',
                'fz44': 'on',        # 44-–§–ó
                'fz223': 'on',       # 223-–§–ó
                'af': 'on',          # –î—Ä—É–≥–∏–µ —Ñ–µ–¥–µ—Ä–∞–ª—å–Ω—ã–µ –∑–∞–∫–æ–Ω—ã
                'ca': 'on',          # –ö–æ–Ω–∫—É—Ä—Å—ã —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–º —É—á–∞—Å—Ç–∏–µ–º
                'placingWay0': 'on', # –°–ø–æ—Å–æ–±—ã —Ä–∞–∑–º–µ—â–µ–Ω–∏—è
                'currencyIdGeneral': -1,
                'searchString': query.strip()
            }
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã –µ—Å–ª–∏ –µ—Å—Ç—å
            if filters:
                params.update(self._prepare_real_filters(filters))
            
            logger.info(f"üåê Making REAL request to: {search_url}")
            logger.debug(f"üìù Search params: {params}")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –†–ï–ê–õ–¨–ù–´–ô –∑–∞–ø—Ä–æ—Å
            async with self.session.get(search_url, params=params, allow_redirects=True) as response:
                
                logger.info(f"üì° Response status: {response.status}")
                logger.info(f"üìç Final URL: {response.url}")
                
                if response.status == 200:
                    html = await response.text()
                    logger.info(f"üìÑ Received HTML: {len(html)} characters")
                    
                    # –ü–∞—Ä—Å–∏–º –†–ï–ê–õ–¨–ù–´–ï —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                    results = self._parse_real_search_results(html)
                    
                    if results:
                        logger.info(f"‚úÖ Successfully parsed {len(results)} REAL tenders")
                        
                        # –ü–æ–ª—É—á–∞–µ–º –¥–µ—Ç–∞–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ —Ç–µ–Ω–¥–µ—Ä–∞
                        enhanced_results = []
                        for result in results[:limit]:
                            try:
                                # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–¥–µ—Ä–∂–∫—É –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
                                await asyncio.sleep(0.5)
                                
                                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–µ—Ç–∞–ª–∏
                                enhanced_result = await self._enhance_tender_data(result)
                                enhanced_results.append(enhanced_result or result)
                                
                            except Exception as e:
                                logger.warning(f"‚ö†Ô∏è Could not enhance tender {result.get('reg_number')}: {e}")
                                enhanced_results.append(result)
                        
                        logger.info(f"üéØ Returning {len(enhanced_results)} REAL tenders")
                        return enhanced_results
                    else:
                        logger.warning(f"‚ùå No tenders found for query: '{query}'")
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–ª–∏ –ª–∏ –Ω–∞—Å
                        if "–∫–∞–ø—á–∞" in html.lower() or "captcha" in html.lower():
                            logger.error("üö´ CAPTCHA detected - need to handle")
                            raise Exception("–°–∞–π—Ç –∑–∞–ø—Ä–æ—Å–∏–ª –∫–∞–ø—á—É. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
                        
                        return []
                        
                elif response.status == 403:
                    logger.error("üö´ Access forbidden (403) - possible blocking")
                    raise Exception("–î–æ—Å—Ç—É–ø –∫ —Å–∞–π—Ç—É –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
                    
                elif response.status == 429:
                    logger.error("‚è∞ Too many requests (429) - rate limited")
                    raise Exception("–°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")
                    
                else:
                    logger.error(f"‚ùå Request failed with status: {response.status}")
                    error_text = await response.text()
                    logger.debug(f"Error response: {error_text[:500]}...")
                    raise Exception(f"–û—à–∏–±–∫–∞ —Å–∞–π—Ç–∞: HTTP {response.status}")
            
        except Exception as e:
            logger.error(f"‚ùå Error in REAL search: {str(e)}")
            raise
    
    async def _initialize_session(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–µ—Å—Å–∏–∏ - –ø–æ–ª—É—á–∞–µ–º cookies —Å –≥–ª–∞–≤–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã"""
        try:
            logger.info("üîÑ Initializing session with zakupki.gov.ru")
            
            async with self.session.get(f"{self.base_url}/epz/main/public/home.html") as response:
                if response.status == 200:
                    logger.info("‚úÖ Session initialized successfully")
                    await asyncio.sleep(1)  # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫—É cookies
                else:
                    logger.warning(f"‚ö†Ô∏è Session initialization returned: {response.status}")
                    
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Session initialization failed: {e}")
    
    def _parse_real_search_results(self, html: str) -> List[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –†–ï–ê–õ–¨–ù–´–• —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –ø–æ–∏—Å–∫–∞ —Å zakupki.gov.ru"""
        soup = BeautifulSoup(html, 'html.parser')
        results = []
        
        logger.debug("üîç Parsing REAL HTML from zakupki.gov.ru")
        
        # –ò—â–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        containers_to_try = [
            {'id': 'searchResultPlaceHolder'},  # –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä
            {'class': 'search-results'},
            {'class': 'registry-entry-list'}
        ]
        
        results_container = None
        for container_selector in containers_to_try:
            results_container = soup.find('div', container_selector)
            if results_container:
                logger.debug(f"‚úÖ Found results container: {container_selector}")
                break
        
        if not results_container:
            logger.warning("‚ùå Results container not found in HTML")
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º HTML –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            with open('debug_search_results.html', 'w', encoding='utf-8') as f:
                f.write(html)
            logger.info("üíæ Saved HTML to debug_search_results.html for analysis")
            return []
        
        # –ò—â–µ–º –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–µ–Ω–¥–µ—Ä–æ–≤ (–∞–∫—Ç—É–∞–ª—å–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è 2025)
        selectors_to_try = [
            'div.row.no-gutters.registry-entry__form',  # –ù–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç
            'div.search-registry-entry-block',          # –°—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç
            'div.registry-entry',                       # –ó–∞–ø–∞—Å–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç
            'div[class*="registry-entry"]'              # –õ—é–±—ã–µ registry-entry
        ]
        
        tender_cards = []
        for selector in selectors_to_try:
            tender_cards = results_container.select(selector)
            if tender_cards:
                logger.debug(f"‚úÖ Found {len(tender_cards)} tender cards with selector: {selector}")
                break
        
        if not tender_cards:
            logger.warning("‚ùå No tender cards found")
            return []
        
        logger.info(f"üéØ Processing {len(tender_cards)} REAL tender cards")
        
        # –ü–∞—Ä—Å–∏–º –∫–∞–∂–¥—É—é –∫–∞—Ä—Ç–æ—á–∫—É
        for i, card in enumerate(tender_cards):
            try:
                result = self._parse_real_tender_card(card)
                if result:
                    results.append(result)
                    logger.debug(f"‚úÖ Parsed tender {i+1}: {result.get('reg_number', 'N/A')}")
                else:
                    logger.debug(f"‚ö†Ô∏è Failed to parse tender card {i+1}")
                    
            except Exception as e:
                logger.error(f"‚ùå Error parsing tender card {i+1}: {str(e)}")
                continue
        
        logger.info(f"‚úÖ Successfully parsed {len(results)} REAL tenders")
        return results
    
    def _parse_real_tender_card(self, card) -> Optional[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ–¥–Ω–æ–π –†–ï–ê–õ–¨–ù–û–ô –∫–∞—Ä—Ç–æ—á–∫–∏ —Ç–µ–Ω–¥–µ—Ä–∞"""
        try:
            data = {}
            
            # 1. –ù–æ–º–µ—Ä —Ç–µ–Ω–¥–µ—Ä–∞ - –ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û
            reg_number = self._extract_real_reg_number(card)
            if not reg_number:
                logger.debug("‚ùå No registration number found")
                return None
            
            data['reg_number'] = reg_number
            
            # 2. –ó–∞–≥–æ–ª–æ–≤–æ–∫ (–Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–Ω–¥–µ—Ä–∞)
            title = self._extract_real_title(card)
            data['title'] = title or f'–¢–µ–Ω–¥–µ—Ä ‚Ññ {reg_number}'
            
            # 3. –ó–∞–∫–∞–∑—á–∏–∫
            customer = self._extract_real_customer(card)
            data['customer'] = customer or '–ó–∞–∫–∞–∑—á–∏–∫ –Ω–µ —É–∫–∞–∑–∞–Ω'
            
            # 4. –¶–µ–Ω–∞
            price = self._extract_real_price(card)
            data['initial_price'] = price
            
            # 5. URL –Ω–∞ –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É
            source_url = self._extract_real_url(card, reg_number)
            data['source_url'] = source_url
            
            # 6. –¢–∏–ø —Ç–µ–Ω–¥–µ—Ä–∞ (44-–§–ó, 223-–§–ó –∏ —Ç.–¥.)
            tender_type = self._determine_real_tender_type(card)
            data['tender_type'] = tender_type
            
            # 7. –°—Ç–∞—Ç—É—Å
            status = self._determine_real_status(card)
            data['status'] = status
            
            # 8. –î–µ–¥–ª–∞–π–Ω –ø–æ–¥–∞—á–∏ –∑–∞—è–≤–æ–∫
            deadline = self._extract_real_deadline(card)
            data['deadline'] = deadline
            
            # 9. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
            data['parsed_at'] = datetime.now()
            data['data_source'] = 'zakupki.gov.ru'
            
            logger.debug(f"‚úÖ Successfully parsed: {reg_number} - {title[:50]}...")
            return data
            
        except Exception as e:
            logger.error(f"‚ùå Error parsing real tender card: {str(e)}")
            return None
    
    def _extract_real_reg_number(self, card) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –†–ï–ê–õ–¨–ù–û–ì–û –Ω–æ–º–µ—Ä–∞ —Ç–µ–Ω–¥–µ—Ä–∞"""
        selectors = [
            '.registry-entry__header-mid__number',
            '.registry-entry__body-number',
            'span[class*="number"]',
            'div[class*="number"]',
            '[data-number]',
            '.number'
        ]
        
        for selector in selectors:
            elem = card.select_one(selector)
            if elem:
                # –ü—Ä–æ–±—É–µ–º –∞—Ç—Ä–∏–±—É—Ç data-number
                reg_number = elem.get('data-number', '').strip()
                if reg_number:
                    return reg_number
                
                # –ü—Ä–æ–±—É–µ–º —Ç–µ–∫—Å—Ç —ç–ª–µ–º–µ–Ω—Ç–∞
                text = elem.get_text(strip=True)
                if text:
                    # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã
                    reg_number = re.sub(r'[‚Ññ#\s]', '', text)
                    if re.match(r'\d{19,}', reg_number):  # –ù–æ–º–µ—Ä–∞ —Ç–µ–Ω–¥–µ—Ä–æ–≤ –æ–±—ã—á–Ω–æ –¥–ª–∏–Ω–Ω—ã–µ
                        return reg_number
        
        # –ò—â–µ–º –Ω–æ–º–µ—Ä –≤ –ª—é–±–æ–º —Ç–µ–∫—Å—Ç–µ –∫–∞—Ä—Ç–æ—á–∫–∏
        full_text = card.get_text()
        reg_match = re.search(r'‚Ññ?\s*(\d{19,})', full_text)
        if reg_match:
            return reg_match.group(1)
        
        return None
    
    def _extract_real_title(self, card) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –†–ï–ê–õ–¨–ù–û–ì–û –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–µ–Ω–¥–µ—Ä–∞"""
        selectors = [
            '.registry-entry__body-value a',
            '.registry-entry__body-value',
            'a[href*="common-info"]',
            'a[title]',
            '.registry-entry__body .d-block',
            '.entry-title',
            'h3 a',
            'h4 a'
        ]
        
        for selector in selectors:
            elem = card.select_one(selector)
            if elem:
                # –°–Ω–∞—á–∞–ª–∞ –∞—Ç—Ä–∏–±—É—Ç title
                title = elem.get('title', '').strip()
                if title and len(title) > 10:
                    return self._clean_title(title)
                
                # –ó–∞—Ç–µ–º —Ç–µ–∫—Å—Ç —ç–ª–µ–º–µ–Ω—Ç–∞
                text = elem.get_text(strip=True)
                if text and len(text) > 10:
                    return self._clean_title(text)
        
        return None
    
    def _extract_real_customer(self, card) -> Optional[str]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –†–ï–ê–õ–¨–ù–û–ì–û –∑–∞–∫–∞–∑—á–∏–∫–∞"""
        selectors = [
            '.registry-entry__body-href',
            '.purchaser',
            'a[href*="purchaser"]',
            '.customer',
            '.registry-entry__body .text-truncate',
            '.organization'
        ]
        
        for selector in selectors:
            elem = card.select_one(selector)
            if elem:
                text = elem.get_text(strip=True)
                if text and len(text) > 3:
                    return self._clean_customer_name(text)
        
        return None
    
    def _extract_real_price(self, card) -> float:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –†–ï–ê–õ–¨–ù–û–ô —Ü–µ–Ω—ã"""
        selectors = [
            '.price-block__value',
            '.cost .currency',
            '.price',
            'span[class*="price"]',
            '.amount'
        ]
        
        for selector in selectors:
            elem = card.select_one(selector)
            if elem:
                price_text = elem.get_text(strip=True)
                price = self._parse_real_price(price_text)
                if price > 0:
                    return price
        
        # –ü–æ–∏—Å–∫ —Ü–µ–Ω—ã –≤ –ª—é–±–æ–º —Ç–µ–∫—Å—Ç–µ
        full_text = card.get_text()
        price_matches = re.findall(r'(?:—Ü–µ–Ω–∞|—Å—Ç–æ–∏–º–æ—Å—Ç—å|—Å—É–º–º–∞).*?(\d[\d\s,]*(?:\.\d+)?)', full_text.lower())
        
        for match in price_matches:
            price = self._parse_real_price(match)
            if price > 1000:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è —Ä–∞–∑—É–º–Ω–∞—è —Ü–µ–Ω–∞
                return price
        
        return 0.0
    
    def _extract_real_url(self, card, reg_number: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –†–ï–ê–õ–¨–ù–û–ô —Å—Å—ã–ª–∫–∏ –Ω–∞ —Ç–µ–Ω–¥–µ—Ä"""
        # –ò—â–µ–º –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É
        selectors = [
            'a[href*="common-info"]',
            'a[href*="view"]',
            '.registry-entry__body-value a'
        ]
        
        for selector in selectors:
            elem = card.select_one(selector)
            if elem and elem.get('href'):
                relative_url = elem['href']
                return urljoin(self.base_url, relative_url)
        
        # –°–æ–∑–¥–∞–µ–º —Å—Å—ã–ª–∫—É –ø–æ —à–∞–±–ª–æ–Ω—É, –µ—Å–ª–∏ –ø—Ä—è–º–∞—è —Å—Å—ã–ª–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞
        if reg_number:
            # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã URL –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ç–µ–Ω–¥–µ—Ä–æ–≤
            url_templates = [
                f"{self.base_url}/epz/order/notice/ea44/view/common-info.html?regNumber={reg_number}",
                f"{self.base_url}/epz/order/notice/ok44/view/common-info.html?regNumber={reg_number}",
                f"{self.base_url}/epz/order/notice/oa44/view/common-info.html?regNumber={reg_number}",
                f"{self.base_url}/epz/order/notice/ok504/view/common-info.html?regNumber={reg_number}"
            ]
            return url_templates[0]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–π —à–∞–±–ª–æ–Ω
        
        return f"{self.base_url}/epz/order/extendedsearch/results.html"
    
    def _determine_real_tender_type(self, card) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –†–ï–ê–õ–¨–ù–û–ì–û —Ç–∏–ø–∞ —Ç–µ–Ω–¥–µ—Ä–∞"""
        text = card.get_text().upper()
        
        if '44-–§–ó' in text or '44-FZ' in text:
            return '44-fz'
        elif '223-–§–ó' in text or '223-FZ' in text:
            return '223-fz'
        elif '–ö–û–ú–ú–ï–†–ß–ï–°–ö' in text:
            return 'commercial'
        else:
            return 'unknown'
    
    def _determine_real_status(self, card) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –†–ï–ê–õ–¨–ù–û–ì–û —Å—Ç–∞—Ç—É—Å–∞ —Ç–µ–Ω–¥–µ—Ä–∞"""
        text = card.get_text().lower()
        
        if any(word in text for word in ['–∑–∞–≤–µ—Ä—à–µ–Ω', 'completed', '–æ–∫–æ–Ω—á–µ–Ω']):
            return 'completed'
        elif any(word in text for word in ['–æ—Ç–º–µ–Ω–µ–Ω', 'cancelled', '–∞–Ω–Ω—É–ª–∏—Ä–æ–≤–∞–Ω']):
            return 'cancelled'
        elif any(word in text for word in ['—á–µ—Ä–Ω–æ–≤–∏–∫', 'draft', '–ø—Ä–æ–µ–∫—Ç']):
            return 'draft'
        else:
            return 'active'
    
    def _extract_real_deadline(self, card) -> Optional[datetime]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –†–ï–ê–õ–¨–ù–û–ì–û –¥–µ–¥–ª–∞–π–Ω–∞"""
        selectors = [
            '.deadline',
            '.date',
            '.data-block__value',
            '[class*="date"]'
        ]
        
        for selector in selectors:
            elem = card.select_one(selector)
            if elem:
                date_text = elem.get_text(strip=True)
                deadline = self._parse_real_date(date_text)
                if deadline:
                    return deadline
        
        # –ò—â–µ–º –¥–∞—Ç—É –≤ –ª—é–±–æ–º —Ç–µ–∫—Å—Ç–µ
        full_text = card.get_text()
        date_patterns = [
            r'–¥–æ\s+(\d{1,2}\.\d{1,2}\.\d{4})\s*(\d{1,2}:\d{2})?',
            r'(\d{1,2}\.\d{1,2}\.\d{4})\s+(\d{1,2}:\d{2})',
            r'(\d{1,2}/\d{1,2}/\d{4})\s+(\d{1,2}:\d{2})'
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, full_text)
            if match:
                try:
                    date_str = match.group(1)
                    time_str = match.group(2) if match.lastindex > 1 else '23:59'
                    
                    if '.' in date_str:
                        return datetime.strptime(f"{date_str} {time_str}", '%d.%m.%Y %H:%M')
                    else:
                        return datetime.strptime(f"{date_str} {time_str}", '%d/%m/%Y %H:%M')
                except ValueError:
                    continue
        
        return None
    
    async def _enhance_tender_data(self, basic_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –†–ï–ê–õ–¨–ù–´–• –¥–∞–Ω–Ω—ã—Ö –æ —Ç–µ–Ω–¥–µ—Ä–µ"""
        try:
            reg_number = basic_data.get('reg_number')
            if not reg_number:
                return basic_data
            
            detailed_data = await self.parse_tender_details(reg_number)
            
            if detailed_data:
                # –û–±—ä–µ–¥–∏–Ω—è–µ–º –±–∞–∑–æ–≤—ã–µ –∏ –¥–µ—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                enhanced = basic_data.copy()
                enhanced.update(detailed_data)
                return enhanced
            
            return basic_data
            
        except Exception as e:
            logger.debug(f"Could not enhance data for {basic_data.get('reg_number')}: {e}")
            return basic_data
    
    @retry(stop=stop_after_attempt(3), wait=wait_exponential(multiplier=1, min=2, max=8))
    async def parse_tender_details(self, reg_number: str) -> Optional[Dict[str, Any]]:
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –†–ï–ê–õ–¨–ù–û–ô –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ —Ç–µ–Ω–¥–µ—Ä–µ
        """
        logger.info(f"üìã Getting REAL tender details for: {reg_number}")
        
        if not self.session:
            raise RuntimeError("Session not initialized")
        
        try:
            # –†–∞–∑–ª–∏—á–Ω—ã–µ URL —à–∞–±–ª–æ–Ω—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ç–µ–Ω–¥–µ—Ä–æ–≤
            url_templates = [
                f"{self.base_url}/epz/order/notice/ea44/view/common-info.html",
                f"{self.base_url}/epz/order/notice/ok44/view/common-info.html",
                f"{self.base_url}/epz/order/notice/oa44/view/common-info.html",
                f"{self.base_url}/epz/order/notice/ok504/view/common-info.html"
            ]
            
            for tender_url in url_templates:
                params = {'regNumber': reg_number}
                
                async with self.session.get(tender_url, params=params) as response:
                    if response.status == 200:
                        html = await response.text()
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ —Ä–µ–∞–ª—å–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ —Ç–µ–Ω–¥–µ—Ä–∞
                        if reg_number in html and '–æ–±—â–∏–µ —Å–≤–µ–¥–µ–Ω–∏—è' in html.lower():
                            data = self._parse_real_tender_details(html, reg_number)
                            if data:
                                logger.info(f"‚úÖ REAL details loaded for {reg_number}")
                                return data
                    
                    elif response.status == 404:
                        logger.debug(f"üìç URL {tender_url} returned 404 for {reg_number}")
                        continue
                    else:
                        logger.debug(f"üìç URL {tender_url} returned {response.status}")
            
            logger.warning(f"‚ö†Ô∏è Could not fetch REAL details for {reg_number}")
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Error parsing REAL tender details: {str(e)}")
            return None
    
    def _parse_real_tender_details(self, html: str, reg_number: str) -> Optional[Dict[str, Any]]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –†–ï–ê–õ–¨–ù–û–ô –¥–µ—Ç–∞–ª—å–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ç–µ–Ω–¥–µ—Ä–∞"""
        soup = BeautifulSoup(html, 'html.parser')
        
        try:
            data = {'reg_number': reg_number}
            
            # –ù–∞–∑–≤–∞–Ω–∏–µ
            title_selectors = [
                'span.cardMainInfo__title',
                '.cardMainInfo__title',
                'h1.orgName',
                'h1',
                '.noticeTabBox .active'
            ]
            
            for selector in title_selectors:
                elem = soup.select_one(selector)
                if elem:
                    data['title'] = self._clean_title(elem.get_text(strip=True))
                    break
            
            # –ó–∞–∫–∞–∑—á–∏–∫
            customer_selectors = [
                'span.cardMainInfo__purchaser',
                '.cardMainInfo__purchaser',
                '.purchaser a',
                '.orgName a'
            ]
            
            for selector in customer_selectors:
                elem = soup.select_one(selector)
                if elem:
                    data['customer'] = self._clean_customer_name(elem.get_text(strip=True))
                    break
            
            # –¶–µ–Ω–∞
            price_selectors = [
                'span.cardMainInfo__price',
                '.cardMainInfo__price',
                '.cost .currency'
            ]
            
            for selector in price_selectors:
                elem = soup.select_one(selector)
                if elem:
                    price_text = elem.get_text(strip=True)
                    data['initial_price'] = self._parse_real_price(price_text)
                    break
            
            # –û–ø–∏—Å–∞–Ω–∏–µ
            desc_selectors = [
                '.noticeTabBox .tabContent',
                '.description',
                '.purchaseObjectInfo'
            ]
            
            for selector in desc_selectors:
                elem = soup.select_one(selector)
                if elem:
                    desc_text = elem.get_text(strip=True)
                    if len(desc_text) > 50:  # –¢–æ–ª—å–∫–æ —Å–æ–¥–µ—Ä–∂–∞—Ç–µ–ª—å–Ω—ã–µ –æ–ø–∏—Å–∞–Ω–∏—è
                        data['description'] = desc_text[:2000]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
                        break
            
            logger.debug(f"‚úÖ Parsed REAL details for: {reg_number}")
            return data
            
        except Exception as e:
            logger.error(f"‚ùå Error parsing REAL tender details HTML: {str(e)}")
            return None
    
    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è –æ—á–∏—Å—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    
    def _clean_title(self, title: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–µ–Ω–¥–µ—Ä–∞"""
        if not title:
            return ''
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã –∏ —Å–∏–º–≤–æ–ª—ã
        cleaned = re.sub(r'\s+', ' ', title.strip())
        
        # –£–±–∏—Ä–∞–µ–º HTML —Ç–µ–≥–∏ –µ—Å–ª–∏ –æ—Å—Ç–∞–ª–∏—Å—å
        cleaned = re.sub(r'<[^>]+>', '', cleaned)
        
        return cleaned[:500]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
    
    def _clean_customer_name(self, customer: str) -> str:
        """–û—á–∏—Å—Ç–∫–∞ –Ω–∞–∑–≤–∞–Ω–∏—è –∑–∞–∫–∞–∑—á–∏–∫–∞"""
        if not customer:
            return ''
        
        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        cleaned = re.sub(r'\s+', ' ', customer.strip())
        
        # –£–±–∏—Ä–∞–µ–º —Ç–∏–ø–∏—á–Ω—ã–µ –ø—Ä–µ—Ñ–∏–∫—Å—ã
        prefixes_to_remove = [
            '–∑–∞–∫–∞–∑—á–∏–∫:', '–æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è:', '–ø–æ–∫—É–ø–∞—Ç–µ–ª—å:',
            'customer:', 'organization:'
        ]
        
        for prefix in prefixes_to_remove:
            if cleaned.lower().startswith(prefix):
                cleaned = cleaned[len(prefix):].strip()
        
        return cleaned[:300]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
    
    def _parse_real_price(self, price_text: str) -> float:
        """–ü–∞—Ä—Å–∏–Ω–≥ –†–ï–ê–õ–¨–ù–û–ô —Ü–µ–Ω—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not price_text:
            return 0.0
        
        # –£–¥–∞–ª—è–µ–º –≤—Å–µ –∫—Ä–æ–º–µ —Ü–∏—Ñ—Ä, –ø—Ä–æ–±–µ–ª–æ–≤, –∑–∞–ø—è—Ç—ã—Ö –∏ —Ç–æ—á–µ–∫
        clean_text = re.sub(r'[^\d\s,.]', '', price_text)
        
        # –ó–∞–º–µ–Ω—è–µ–º –∑–∞–ø—è—Ç—ã–µ –Ω–∞ —Ç–æ—á–∫–∏ –∏ —É–±–∏—Ä–∞–µ–º –ø—Ä–æ–±–µ–ª—ã
        clean_text = clean_text.replace(',', '.').replace(' ', '')
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —á–∏—Å–ª–∞
        numbers = re.findall(r'\d+(?:\.\d+)?', clean_text)
        
        if numbers:
            try:
                # –ë–µ—Ä–µ–º —Å–∞–º–æ–µ –±–æ–ª—å—à–æ–µ —á–∏—Å–ª–æ (—Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ —Ü–µ–Ω–∞)
                prices = [float(num) for num in numbers]
                max_price = max(prices)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—É–º–Ω–æ—Å—Ç—å —Ü–µ–Ω—ã
                if max_price > 1000000000:  # –ë–æ–ª—å—à–µ 1 –º–ª—Ä–¥ - –≤–æ–∑–º–æ–∂–Ω–æ –æ—à–∏–±–∫–∞ –≤ –∫–æ–ø–µ–π–∫–∞—Ö
                    max_price = max_price / 100
                
                return max_price
                
            except (ValueError, TypeError):
                return 0.0
        
        return 0.0
    
    def _parse_real_date(self, date_text: str) -> Optional[datetime]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –†–ï–ê–õ–¨–ù–û–ô –¥–∞—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        if not date_text:
            return None
        
        # –†–∞–∑–ª–∏—á–Ω—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã –¥–∞—Ç
        date_patterns = [
            (r'(\d{1,2})\.(\d{1,2})\.(\d{4})\s+(\d{1,2}):(\d{2})', '%d.%m.%Y %H:%M'),
            (r'(\d{1,2})\.(\d{1,2})\.(\d{4})', '%d.%m.%Y'),
            (r'(\d{1,2})/(\d{1,2})/(\d{4})\s+(\d{1,2}):(\d{2})', '%d/%m/%Y %H:%M'),
            (r'(\d{1,2})/(\d{1,2})/(\d{4})', '%d/%m/%Y'),
            (r'(\d{4})-(\d{1,2})-(\d{1,2})\s+(\d{1,2}):(\d{2})', '%Y-%m-%d %H:%M'),
            (r'(\d{4})-(\d{1,2})-(\d{1,2})', '%Y-%m-%d')
        ]
        
        for pattern, format_str in date_patterns:
            match = re.search(pattern, date_text)
            if match:
                try:
                    if len(match.groups()) == 5:  # –° –≤—Ä–µ–º–µ–Ω–µ–º
                        date_str = f"{match.group(1)}.{match.group(2)}.{match.group(3)} {match.group(4)}:{match.group(5)}"
                        return datetime.strptime(date_str, format_str)
                    else:  # –¢–æ–ª—å–∫–æ –¥–∞—Ç–∞
                        date_str = f"{match.group(1)}.{match.group(2)}.{match.group(3)}"
                        return datetime.strptime(date_str, format_str.split()[0])
                        
                except ValueError:
                    continue
        
        return None
    
    def _prepare_real_filters(self, filters: Dict[str, Any]) -> Dict[str, str]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –†–ï–ê–õ–¨–ù–´–• —Ñ–∏–ª—å—Ç—Ä–æ–≤ –¥–ª—è zakupki.gov.ru"""
        params = {}
        
        if 'price_from' in filters and filters['price_from']:
            params['priceFromGeneral'] = str(filters['price_from'])
        
        if 'price_to' in filters and filters['price_to']:
            params['priceToGeneral'] = str(filters['price_to'])
        
        if 'date_from' in filters and filters['date_from']:
            params['publishDateFrom'] = str(filters['date_from'])
        
        if 'date_to' in filters and filters['date_to']:
            params['publishDateTo'] = str(filters['date_to'])
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è zakupki.gov.ru
        if 'region' in filters and filters['region']:
            params['selectedSubjectsIdNameHidden'] = str(filters['region'])
        
        return params